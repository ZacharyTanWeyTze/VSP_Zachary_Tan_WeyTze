{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "56fb16cb",
      "metadata": {
        "id": "56fb16cb"
      },
      "source": [
        "## Lab Assignment 6 -- Regression\n",
        "In this lab, you will complete an exercises related to the lecture material on regression. Then, you will compete with your fellow classmates to see who can best predict housing prices.\n",
        "\n",
        "**IMPORTANT:** Before submitting, make sure you restart the kernel and run all cells sequentially. After all cells have executed, then save the file for submission.  This is very important for grading."
      ]
    },
    {
      "cell_type": "code",
      "id": "3fa22484",
      "metadata": {
        "id": "3fa22484"
      },
      "source": [
        "# Don't change this line\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics\n",
        "import pandas as pd\n",
        "np.random.seed(35)"
      ],
      "outputs": [],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "id": "a8137271",
      "metadata": {
        "id": "a8137271"
      },
      "source": [
        "## Exercise 1 -- Generating & Analyzing Fake Data\n",
        "In this exercise, we will generate some fake data as we did in the lecture on regression trees. Then, we will use it on a series of regression problems."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "509af2e9",
      "metadata": {
        "id": "509af2e9"
      },
      "source": [
        "## Exercise 1a -- Generating the Data\n",
        "Complete the following steps:\n",
        "1. Define a function called `generate_data` that takes two arguments, an integer `n` and a boolean `square`. `square` should have a default argument of `False`.\n",
        "2. Generate an array called `X` and set it equal to `np.random.randn((n,1))`. This creates an $n$-vector of [**standard normal random variables**](https://en.wikipedia.org/wiki/Normal_distribution).\n",
        "3. Turn `X` into an $nx2$ array by concatenating it with an $n$-vector of ones (**Hint**: use `np.ones((n,1))` and `np.concatenate()`). Make sure that the array of ones serves as the first column.\n",
        "3. Define an array called `beta` and set it equal to the array [1, 3.14]\n",
        "4. Define a variable called `epsilon` and set it equal to `np.random.randn(n)*0.3`\n",
        "5. Then, using `X`, `beta`, and `epsilon`, create a variable named `y` which is equal to\n",
        "    - `np.matmul(X, beta) + epsilon` if square is `False`\n",
        "    - `np.matmul(X ** 2, beta) + epsilon` if `square` is `True`.\n",
        "    \n",
        "6. Your output should return `X`and `y`\n",
        "7. Test your function in the cell below with `n=100` and no argument for `square`. Save the output to `X100` and `y100` respectively. Afterwards, print `y100[50]`.\n",
        "\n",
        "Answer the following questions in the Markdown cell below:\n",
        "1. Is this a bivariate or multivariate linear regression model? Why?\n",
        "2. What is the purpose of  including this `epsilon`? What aspect of real data are we trying to mimic?"
      ]
    },
    {
      "cell_type": "code",
      "id": "c847213c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c847213c",
        "outputId": "c389d7b2-e04d-4a18-aa4a-3dfc89cb9deb"
      },
      "source": [
        "# Exercise 1a -- Test function and print\n",
        "def generate_data(n, square = False):\n",
        "  # Generate an n-vector of standard normal random variables\n",
        "  x = np.random.randn(n, 1)\n",
        "\n",
        "  # Concatenate an n-vector of ones to create an n x 2 array\n",
        "  x = np.concatenate((np.ones((n, 1)), x), axis=1)\n",
        "\n",
        "  # Define beta\n",
        "  beta = np.array([1, 3.14])\n",
        "\n",
        "  # Generate epsilon\n",
        "  epsilon = np.random.randn(n)*0.3\n",
        "\n",
        "  # Create y based on square argument\n",
        "  if square == False:\n",
        "    y = np.matmul(x, beta) + epsilon\n",
        "  else:\n",
        "    y = np.matmul(x ** 2, beta) + epsilon\n",
        "\n",
        "  return x, y\n",
        "\n",
        "# Test the function with n=100 and no argument for square\n",
        "X100, y100 = generate_data(100)\n",
        "print(y100[50])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-2.855072207243597\n"
          ]
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "markdown",
      "id": "d9d47ea4",
      "metadata": {
        "id": "d9d47ea4"
      },
      "source": [
        "### Reponse to Exercise 1a\n",
        "Zachary:\n",
        "* Q1. This is a bivariate linear regression model because it predicts the dependent variable y using two independent variables: the constant term (the column of ones) and the random variable X.\n",
        "* Q2. The purpose of including epsilon is to add random noise to the linear relationship between X and y. In real-world data, there are always unexplained variations from inherent randomness. The epsilon variable mimics these real-world randomness."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be3ee923",
      "metadata": {
        "id": "be3ee923"
      },
      "source": [
        "## Exercise 1b -- Standard Linear Regression\n",
        "Using `sklearn`, fit a linear regression model on `y100` and `X100`. When intializing your model, set `fit_intercept` equal to `False` and call your linear model `lr_model_1`. Then, print the estimated coefficients and answer the following question in the Markdown cell below.\n",
        "- What are the coefficient estimates? What values are they close to? Why does this make sense?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "f9955e7f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9955e7f",
        "outputId": "d1ad44eb-8ee2-4e03-c9c8-739558464692"
      },
      "source": [
        "# Exercise 1b -- fit regression\n",
        "# Import the LR model from sklearn\n",
        "from sklearn import linear_model\n",
        "\n",
        "# Initialize model\n",
        "lr_model_1 = linear_model.LinearRegression(fit_intercept=False)\n",
        "\n",
        "# Fit model using X100 and y100\n",
        "lr_model_1.fit(X100, y100)\n",
        "\n",
        "# Print coefficients\n",
        "beta_0 = lr_model_1.intercept_\n",
        "beta_1 = lr_model_1.coef_[0]\n",
        "\n",
        "print(f\"lr_model_1: y = {beta_0:.4f} + {beta_1:.4f} X\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lr_model_1: y = 0.0000 + 1.0134 X\n"
          ]
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "id": "d0d5d044",
      "metadata": {
        "id": "d0d5d044"
      },
      "source": [
        "### Response to Exercise 1b\n",
        "Zachary: The constant is 0 and the coefificent of X is 1.02 (2 d.p). They are close to 0 and 1 respectively. The constant of 0 makes sense because we asked the LR model to use no intercept, thus when X = 0, y = 0. The coefficent of X being near 1 makes sense because the X and y values in the dataset should be about the same as they were randomly generated using similar random functions."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "085c9960",
      "metadata": {
        "id": "085c9960"
      },
      "source": [
        "## Exercise 1c -- Linear Regression with Quadratic Terms\n",
        "Using `generate_data(100, True)`, create two variables `y100_2` and `X100_2`. Then, repeat the steps from **Exercise 1b** above using `X100_2` and `y100_2` instead of `X_100` and `y_100`.  Call your new model `linear_model_2`.\n",
        "\n",
        "Answer the following questions in the Markdown cell below:\n",
        "\n",
        "1. What are the coefficient estimates? Are they similar to the coefficients from **Exercise 1b**? Why or why not?\n",
        "\n",
        "If your estimates were not similar, create a variable `X100_2_sq` in the third cell below that can be used instead of `X100_2` so that your estimates are similar again. Repeat the same process again but call your `lr_model_3`. Print your new estimated coefficients.\n",
        "\n",
        "In the markdown cell below, answer the following question:\n",
        "\n",
        "2. How did you modify `X100_2` to attain similar coefficients? Why did this work?"
      ]
    },
    {
      "cell_type": "code",
      "id": "be504991",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "be504991",
        "outputId": "964a513d-e13a-4c67-9720-965682d36cdf"
      },
      "source": [
        "# Exercise 1c -- generate variables and repeat regression fit\n",
        "# Create X100_2 and y100_2\n",
        "X100_2, y100_2 = generate_data(100, True)\n",
        "\n",
        "# Initialize model\n",
        "lr_model_2 = linear_model.LinearRegression(fit_intercept=False)\n",
        "\n",
        "# Fit model using X100_2 and y100_2\n",
        "lr_model_2.fit(X100_2, y100_2)\n",
        "\n",
        "# Print coefficients\n",
        "beta_0 = lr_model_2.intercept_\n",
        "beta_1 = lr_model_2.coef_[0]\n",
        "\n",
        "print(f\"lr_model_2: y = {beta_0:.4f} + {beta_1:.4f} X\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lr_model_2: y = 0.0000 + 3.9659 X\n"
          ]
        }
      ],
      "execution_count": 4
    },
    {
      "cell_type": "markdown",
      "id": "064117e4",
      "metadata": {
        "id": "064117e4"
      },
      "source": [
        "### Response to Exercise 1c -- Question 1\n",
        "Zachary: The constant is 0, the coefficent of X is approxinately between 3-5. The constant is the same but the X coefficent is not similar to that of Exercise 1b, it is much bigger. The y values this time have been generated and derived from X^2."
      ]
    },
    {
      "cell_type": "code",
      "id": "af3c6cd1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af3c6cd1",
        "outputId": "91b23b23-6977-4e0b-ab32-171b144a147c"
      },
      "source": [
        "# Exercise 1c -- modify X100_2 and run new regression\n",
        "# Create X100_2_sq\n",
        "X100_2_sq = X100_2 ** 2\n",
        "\n",
        "# Initialize model\n",
        "lr_model_3 = linear_model.LinearRegression(fit_intercept=False)\n",
        "\n",
        "# Fit model using X100_2_sq and y100_2\n",
        "lr_model_3.fit(X100_2_sq, y100_2)\n",
        "\n",
        "# Print coefficients\n",
        "beta_0 = lr_model_3.intercept_\n",
        "beta_1 = lr_model_3.coef_[0]\n",
        "\n",
        "print(f\"lr_model_3: y = {beta_0:.4f} + {beta_1:.4f} X\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lr_model_3: y = 0.0000 + 0.9921 X\n"
          ]
        }
      ],
      "execution_count": 5
    },
    {
      "cell_type": "markdown",
      "id": "ad67e55d",
      "metadata": {
        "id": "ad67e55d"
      },
      "source": [
        "### Response to Exercise 1c -- Quesiton 2\n",
        "Zachary: I modified X100_2 by squaring it to give me X100_2_sq. The result is that the coefficient of X in lr_model_3 is close to 1 again. This works because The values of y100_2 are approximately the square of X100_2 plus a little. So, squaring X100_2 will give us values close to (but slightly lower) than y100_2, hence why the new coefficient is roughly 0.9 - 1.0."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bebaa1d3",
      "metadata": {
        "id": "bebaa1d3"
      },
      "source": [
        "### Exercise 1d -- Unnecessary Quadratic Terms\n",
        "Now we are going to see what happens when we estimate a model that only has linear terms using both linear and quadratic terms. Complete the following steps:\n",
        "1. Create an $nx3$ array called `X100_ext` by concatenating `X100` with a column that is equal to the square of elements in the second column. Make sure this new column is the third column. Note that `np.concatenate` requires that both arrays are of the same dimension. You may have to use the method [`.reshape()`](https://numpy.org/doc/stable/reference/generated/numpy.reshape.html).\n",
        "2. Now repeat the steps of **Exercise 1b** with `X100_ext`. Make sure you print the estimated coefficients.\n",
        "\n",
        "Answer the following questions in the Markdown cell below:\n",
        "1. Are the first two coefficients different from their respective counterparts in part **Exercise 1b**? Why do you think this is?\n",
        "2.  Is the third coeffcient close to 0 or large? Why do you think this is?\n",
        "3. Do you think these estimates are accurate?"
      ]
    },
    {
      "cell_type": "code",
      "id": "ba894f15",
      "metadata": {
        "scrolled": true,
        "id": "ba894f15"
      },
      "source": [
        "# Exercise 1d -- Create X100_ext here\n",
        "X100_ext = np.concatenate((X100[:,0].reshape(-1,1),\n",
        "                           X100[:,1].reshape(-1,1),\n",
        "                           (X100[:,1] ** 2).reshape(-1,1)), axis=1)"
      ],
      "outputs": [],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "id": "50115717",
      "metadata": {
        "id": "50115717",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67ee5343-7257-411f-98d7-9694d3eada34"
      },
      "source": [
        "# Exercise 1d -- Repeat exercise 1b here\n",
        "# Initialize model\n",
        "lr_model_4 = linear_model.LinearRegression(fit_intercept=False)\n",
        "\n",
        "# Fit model using X100_ext and y100_2\n",
        "lr_model_4.fit(X100_ext, y100_2)\n",
        "\n",
        "# Print coefficients\n",
        "beta_0 = lr_model_4.intercept_\n",
        "beta_1 = lr_model_4.coef_[0]\n",
        "beta_2 = lr_model_4.coef_[1]\n",
        "\n",
        "print(f\"lr_model_4: y = {beta_0:.4f} + {beta_1:.4f} X1  + {beta_2:.4f} X2\" )"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lr_model_4: y = 0.0000 + 4.0685 X1  + 0.4949 X2\n"
          ]
        }
      ],
      "execution_count": 7
    },
    {
      "cell_type": "markdown",
      "id": "a18eab25",
      "metadata": {
        "id": "a18eab25"
      },
      "source": [
        "### Response to Exercise 1d\n",
        "* Q1. The first coefficient is the same as before (0 due to there being no intercept). The second coefficient is different from 1b but the same as 1c.\n",
        "* Q2. The third coefficient is close to 0.\n",
        "* Q3. These estimates are accurate."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b3fd11d",
      "metadata": {
        "id": "7b3fd11d"
      },
      "source": [
        "## Exercise 1e -- Regression Plots\n",
        "Following the notes in the plotting lectures complete the following steps:\n",
        "1. Using `subplots()` initialize a figure with 4 figures in a $2x2$ grid\n",
        "2. Plot the following in the indicated location.\n",
        "    - **Top-left**  -- a line plot of `lr_model_1` and a scatter plot of the data used to generate `lr_model_1`.\n",
        "    - **Bottom-left**  -- a line plot of `lr_model_2` and a scatter plot of the data used to generate `lr_model_2`\n",
        "    - **Bottom-right** -- a line plot of `lr_model_3` and a scatter plot of the data used to generate `lr_model_3`\n",
        "    - **Top-right** -- a line plot of `lr_model_4` and a scatter plot of the data used to generate `lr_model_4`\n",
        "    \n",
        "For the plots above,\n",
        "- make your lines red,\n",
        "- title your plots (e.g. \"Linear Model 1\"),\n",
        "- use `np.linspace(-4,4,200)` as your domain when plotting the lines,\n",
        "- call `fig.tight_layout()` so your plot is not cluttered\n",
        "\n",
        "3. Using the `metrics` submodule of `sklearn`, print the `in-sample` mean squared errors of each model using f strings. Your stings should looke like this: \"MSE of Linear Model 1 is .3\"  \n",
        "**Hints:** .\n",
        "- To plot on the top left axis, you will need to work with `axes.flat[0]` . The remaining axes are indexed by 1, 2, and 3.\n",
        "- If you choose to used the `.predict()` to plot your lines, keep in mind you need to provide it with the correctly shaped input.\n",
        "- When calculating the means within a loop, it may hep to create a list that contains the four linear models.\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "06bb2cad",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "06bb2cad",
        "outputId": "093d66bc-528d-4a0a-d0c9-1593dd463886"
      },
      "source": [
        "# Exercise 1e -- plots\n",
        "# Create domain for line plots\n",
        "domain = np.linspace(-4, 4, 200)\n",
        "\n",
        "# Intialize plots, 4 axes arranged in a 2x2 grid\n",
        "fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n",
        "\n",
        "# Top-left plot\n",
        "axs[0, 0].scatter(X100, y100, color='blue', label='Data')\n",
        "axs[0, 0].plot(domain, lr_model_1.predict(domain.reshape(-1, 1)), color='red', label='Linear Model 1')\n",
        "axs[0, 0].set_title('Linear Model 1')\n",
        "axs[0, 0].legend()\n",
        "\n",
        "# Bottom-left plot\n",
        "axs[1, 0].scatter(X100_2, y100_2, color='blue', label='Data')\n",
        "axs[1, 0].plot(domain, lr_model_2.predict(domain.reshape(-1, 1)), color='red', label='Linear Model 2')\n",
        "axs[1, 0].set_title('Linear Model 2')\n",
        "axs[1, 0].legend()\n",
        "\n",
        "# Bottom-right plot\n",
        "axs[1, 1].scatter(X100_2_q2, y100_2, color='blue', label='Data')\n",
        "axs[1, 1].plot(domain, lr_model_3.predict(domain.reshape(-1, 1)), color='red', label='Linear Model 3')\n",
        "axs[1, 1].set_title('Linear Model 3')\n",
        "axs[1, 1].legend()\n",
        "\n",
        "# Top-right plot\n",
        "axs[0, 1].scatter(X100_ext, y100_2, color='blue', label='Data')\n",
        "axs[0, 1].plot(domain, lr_model_4.predict(domain.reshape(-1, 1)), color='red', label='Linear Model 4')\n",
        "axs[0, 1].set_title('Linear Model 4')\n",
        "axs[0, 1].legend()\n",
        "\n",
        "# Adjust layout\n",
        "fig.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "x and y must be the same size",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-7e121005c59a>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Top-left plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'blue'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_model_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'red'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Linear Model 1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Linear Model 1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1440\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[1;32m   4582\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4583\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4584\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x and y must be the same size\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4586\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must be the same size"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1000 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "execution_count": 9
    },
    {
      "cell_type": "code",
      "id": "83de691e",
      "metadata": {
        "scrolled": true,
        "id": "83de691e"
      },
      "source": [
        "# Exercise 1e -- mean squared errors\n",
        "# Import MSE\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Print MSE for each model\n",
        "y_pred_1 = lr_model_1.predict(X1.reshape(-1, 1))\n",
        "y_pred_2 = lr_model_2.predict(X2.reshape(-1, 1))\n",
        "y_pred_3 = lr_model_3.predict(X3.reshape(-1, 1))\n",
        "y_pred_4 = lr_model_4.predict(X4.reshape(-1, 1))\n",
        "\n",
        "print(f\"MSE of Linear Model 1 is {mean_squared_error(y1, y_pred_1):.3f}\")\n",
        "print(f\"MSE of Linear Model 2 is {mean_squared_error(y2, y_pred_2):.3f}\")\n",
        "print(f\"MSE of Linear Model 3 is {mean_squared_error(y3, y_pred_3):.3f}\")\n",
        "print(f\"MSE of Linear Model 4 is {mean_squared_error(y4, y_pred_4):.3f}\")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "81baa272",
      "metadata": {
        "id": "81baa272"
      },
      "source": [
        "### Exercise 1f -- Functional Misspecification\n",
        "**Functional Misspecification** is used to describe the situation where the functional form of the regression model we are estimating is not the same as the functional form of the true data generating process. Answer the following question in the markdown cell below:\n",
        "- Which of the four linear models do you think are well-specified? Which ones are not? Is including extra terms problematic when it comes to being well-specified. What about excluding the terms found in the true data generating process?\n",
        "- How does misspecification manifest itself in the plots? How about in the mean squared errors?\n",
        "- After doing this exercise, do you think it is important to investigate the relationship between variables before determining your regression specification? Why or why not?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03d3f378",
      "metadata": {
        "id": "03d3f378"
      },
      "source": [
        "### Response to Exercise 1f"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77c7d5c8",
      "metadata": {
        "id": "77c7d5c8"
      },
      "source": [
        "### Exercise 1g -- Lasso\n",
        "Finally, we will run lasso on our fake data. Complete the following steps:\n",
        "1. Generate `X1000` and `y1000` using `generate_data(1000)`\n",
        "2. Create an `1000x3` array called `X1000_ext` which is created in a anaglous fashion to `X100_ext`.\n",
        "3. Follow the lecture notes to create a standardized version of `X1000_ext` called `X1000_ext_scl`. You will need to import the `preprocessing` submodule of sklearn.\n",
        "4. Check to make sure your means and variances. You should see that everything looks good except for our intercept has a variance of $0$. You actually do not want to standardize an intercept but we still need it! Replace the first column of  `X1000_ext_scl` with a fresh column of ones using `np.ones(1000)`.\n",
        "5. Create a dataframe version of `X1000_ext_scl` called `X_lasso_df` and rename the columns to \"intercept\", \"x\", and \"x_sq\" respectively.Then call `X_lasso_df` at the bottom of the cell.\n",
        "6. Copy and paste the Lasso path code from the lecture notes into the second cell below. Adapt it so it works for `X_lasso_df` and `y1000`.\n",
        "\n",
        "\n",
        "In the Markdown cell below, answer the following questions:\n",
        "1. Characterize `X_sq`'s lasso path. Why was this behavior predictable?    Reference linear model 4 or the true DGP in your answer.\n",
        "2. Without checking, do you think a low or high value for alpha would be chosen by cross validation? To help you answer this question, think about what the true coefficients are and whether or not higher alphas bring the lasso coefficients closer to their true counterparts or farther away."
      ]
    },
    {
      "cell_type": "code",
      "id": "c250202b",
      "metadata": {
        "scrolled": false,
        "id": "c250202b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "616d00e5-2caf-4fb9-efaa-44897d7156ed"
      },
      "source": [
        "# Exercise 1g -- Steps 1-5\n",
        "from sklearn import preprocessing\n",
        "\n",
        "X1000, y1000 = generate_data(1000)\n",
        "X1000_ext = np.concatenate((X1000.reshape(-1,1),\n",
        "                           (X1000 ** 2).reshape(-1,1),\n",
        "                            axis = 1)\n",
        "# X1000_ext_scl"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'generate_data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c400edcd60c3>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mX1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1000\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mX1000_ext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1000\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX1000\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mX1000_ext_scl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'generate_data' is not defined"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "4cfec5de",
      "metadata": {
        "scrolled": false,
        "id": "4cfec5de"
      },
      "source": [
        "# Exercise 1g -- Step 5 copy code here\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}